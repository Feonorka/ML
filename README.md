# ML
ML Application
**Основные задачи машинного обучения:**
# Урок 1
* Обучение с учителем
    * Задачи регрессии (предсказывается числовое значение)
        - Линейная регрессия
        - Нелинейная регрессия
        - Решающие деревья  
    * Задачи класификации (ответ дан в виде ранга)
        - Метод ближайших соседей
        - Множественная класификация
* Обучение без учителя
    * Задача кластеризации (предсказание распределения данных)
    * Задачи понижения размерности
    * Задача выявления аномалий (не зная конкретных аномалий, предположить что имеется определенное нормальное распределение параметров и выявить на их фоне аномалии)
* Обучение с подкреплением
---
# Урок 2
**Модель машинного обучения** - некоторая функция или алгоритм, вычислительная особенность, которая по входным параметрам выдает ответ.
Процесс формирования модели ML:
1. Выбор источника данных
2. Постановка цели или метрики
3. [ETL](https://practicum.yandex.ru/blog/chto-takoe-etl/ "Что такое ETL") (Extraction, Transformation, Loading) (Сбор, очистка, объединение)
4. [EDA](https://habr.com/ru/post/719206/ "Что такое EDA") (Exploratory Data Analysis) (Разведочный анализ данных) Обычно проводится единожды
5. Очистка данных
6. Выбор модели и ее обучение
7. Оценка модели (Если оценка плохая - можно вернуться к этапу ETL или даже выбору источника данных)
8. Внедрение модели (интеграция)
---
# Урок 3
**ETL - процесс предподготовке данных. Может выполнятся несколько раз.**
1. Получение данных
2. Очистка данных или заполнение пропусков
    - Интерполяция значений (заполнение пропусков близкими значениями). **Не работает для категориальных данных**, но подходит для числовых и ранговых. Возможно использование для категориальных и числовых возможен вариант с заполнением полей значениями которые точно не встретятся в норме и не будут учавствовать в анализе. Сам по себе пропуск данных исключает возможность использования экзепляра данных для обучения.
    > Мусор на входе - мусор на выходе
3. Объединение данных
---
# Урок 4
**EDA - разведочный или исследовательский анализ данных.**
Задачи EDA:
1. Оценка распределения параметров (равномерное распределение (если имется нормально распределенные числовые данные для линейной регрессии), бимодальное *(возможно требуется разбить данные на две категории, чтобы анализировать их поотдельности)*, по Пуасону или оно отсутствует *(возможно для категориальных данных)*). Предположениео том какая модель машинного обучения может получится и сделать выбор
2. **Поиск пропусков данных** или нулевых значений и аномалий
3. Корреляция. Определиться с поиском наиболее значимых параметров.
4. Примеры данных
В результате даются рекомендации и делаются выводы для **ETL**.
---
# Урок 5
## Препроцессинг данных:
1. Нормирование *(приведение к диапазону 0 <-> 1)*:

| Параметр |  |  |  |  |  |  |  |  |  |
|-----|------|------|------|------|------|------|------|------|------|
| **X** | 1 | 2 | 4 | 5 | **->** | 0 | 1/4 | 3/4 | 1 |
| **Y** | -100 | 300 | 1100|  |**->** | 0 | 1/3 | 1|

> X -> (X - min) / (max - min)

На таких данных можно посчитать любую модель, но если нужно понять какие данные привели к конкретным результатам, то нужно выполнить обратное преобразование.

> X -> (X - avg) / std
2. Z нормирование *(в случае если данные имеют нормальное распределение)* *(приведение к диапазону -3 <-> 3)*
3. Приведение к единичным векторам: [OHE](https://pythonpip.ru/osnovy/one-hot-encoding-python?ysclid=leqrcvf1gd978117076/ "Что такое One-Hot Encoding")
4. Циклические переменные
> Z -> (sin Z; cos Z)

| Параметр |  |  |  |  |  |  |  |  |  |  |  |
|-----|------|------|------|------|------|------|------|------|------|------|------|
| **Z** | 5 | 120 | 360 | **->** |  |  |  |
| **sin Z** | 0,087 | 0,866 | 0 |**->** |  |  | |
| **cos Z** | 0,996 | −0,5 | 1 |**->** |  |  |  |

Преобразование выполняется по правилу:
>sin Z + 1 / 2

>cos Z + 1 / 2
---
# Урок 6
## Разбиение выборки
Разбиение выборки данных для проверки должно соответствовать пропорции *80 / 20* эти доли соотвествуют **Обучающей и Проверочной выборке**

> Сравнивать модели необходимо только с учетом того что они обучались на одинаковых объемах данных

| Общая выборка | 1 000 000 | **I** | K - fold |  |Обучение и валидация|
|-----|------|------|------|------|------|
| Первичная выборка | 1 000 000 | **I** |  | 800 000 | 800 000 |
| **Обучающая** | 800 000 | **I** | **->** | 160 000 * 5 | 640 000 |
| **Проверочная** | 200 000 | **I** |**->** | * | 160 000 |

## Цели:
1. Чтобы хорошо обучить модель (чтобы она получила достаточно большое количество исходных данных)
2. Найти все ошибки и понять где модель обучилась недостаточно хорошо
## Способы :
1. Перекрестная валидация - используется для улучшения модели. Заключается в раздроблении данных на более мелкие равные части и поочередное обучение и проверку модели на разных частях. Позволяет понять насколько модель хорошо работает на обучающей выборке.
> Капитальное разбиение используется для итоговой оценки и сравнения моделей и метрик по точности.

Используется в сложных моделях (градиентный бустинг, случаный лес)

2. Обучающая и валидационные выборки - используются для обучения **нейросетей**. Каждую эпоху нейросеть обучается на обучающем наборе и сравнивает с валидационным. Важно не допустить переобучения и остановить обучение в тот момент когда разница в точности обученной модели и валидационной выборки начнет увеличиваться.
![График обучения](/ML\fitgraph.bmp "Процесс обучения модели")

3. Если параметров очень много то используют метку значений.
4. Иногда используется простое обучение с отдельными параметрами и потом идет сравнение моделей "один к одному" если параметров не много.
---
# Урок 7
## Оптимизация гиперпараметров
*Работа самой модели машинного обучения*.

**Параметры** - сами исходные данные.

**Гиперпараметры** - независимые переменные, на основании которых мы предсказываем решение
|  |  | Компоненты |  | модели |  |  |
|-----|------|------|------|------|------|------|
| **Ответ** | + | **Параметр** | + | **Оптимизация** | **->** | **Результат работы ML** |

### **Жадный поиск (по сетке):**
Выбор предполагаемых значений параметров в определенном диапазоне с выбранным шагом. Путем перемножения количества вариантов каждого параметра друг на друга получается число **возможных _гиперпараметров модели._** Среди них будет комбинация наилучших параметров. Поиск выполняется при помощи **K - fold** валидации и проверяется на данном наборе гипперпараметров. Происходит поиск глобального минимума ошибки и уже в нем вычисляется оптимальное значение гиперпараметра.

> Недостаток - можно попасть в локальный минимум
### **Случайный поиск:**
Тот же принцип, только берется определенное число вариантов комбинаций гиперпараметров (сетка определенного размера) и происходит поиск.

> Недостаток - можно попасть в локальный минимум

Чем мельче сетка тем больше гарантия того что будет найден оптимальный набор гиперпараметров.

**Оптимизация гиперпараметров не способна сильно повлиять на качество модели.** Ее применяют для *"настроки"* модели на финальной стадии.

> **При наблюдении сильных проблем с точностью следует рассмотреть выбор другой модели или воспользоваться ансамблем моделей.**
---
# Урок 8
## Неодообучение
Обученная модель машинного обучения дает нам точность ниже ожидаемой на проверочной выбрке.
### Причины:
1. Не проведена опимизация гиперпараметров модели
2. Ранняя остановка обучения
3. Выбор неверной функции ошибки для модели
4. Неверная модель
## Переобучение
С нейроными сетями отследить просто. С классификационными моделям или линейными моделями - сложнее предотвратить.
> Выход: использование ансанбля моделей
### Решение:
Проведение проверки зависимости данных от ошибки не только на валидационном наборе (ошибка перестанет падать или пойдет на увеличение), но и на проверочном наборе.
**Валидационная выборка** - извлечение нескольких точек из обучающей выборке, не учавствующих в обучении 

> **В случае использования ансамбля добавить модель на этапе начала ее *"переобучения"* для того чтобы проводить обучение внутри ансамбля, ориентируясь на разрывы в ошибках.**
---
# Урок 9
## Смещение
## Разброс
## Ошибка данных

