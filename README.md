# ML
ML Application
**Основные задачи машинного обучения:**
### Урок 1
* Обучение с учителем
    * Задачи регрессии (предсказывается числовое значение)
        - Линейная регрессия
        - Нелинейная регрессия
        - Решающие деревья  
    * Задачи класификации (ответ дан в виде ранга)
        - Метод ближайших соседей
        - Множественная класификация
* Обучение без учителя
    * Задача кластеризации (предсказание распределения данных)
    * Задачи понижения размерности
    * Задача выявления аномалий (не зная конкретных аномалий, предположить что имеется определенное нормальное распределение параметров и выявить на их фоне аномалии)
* Обучение с подкреплением
---
### Урок 2
**Модель машинного обучения** - некоторая функция или алгоритм, вычислительная особенность, которая по входным параметрам выдает ответ.
Процесс формирования модели ML:
1. Выбор источника данных
2. Постановка цели или метрики
3. [ETL](https://practicum.yandex.ru/blog/chto-takoe-etl/ "Что такое ETL") (Extraction, Transformation, Loading) (Сбор, очистка, объединение)
4. [EDA](https://habr.com/ru/post/719206/ "Что такое EDA") (Exploratory Data Analysis) (Разведочный анализ данных) Обычно проводится единожды
5. Очистка данных
6. Выбор модели и ее обучение
7. Оценка модели (Если оценка плохая - можно вернуться к этапу ETL или даже выбору источника данных)
8. Внедрение модели (интеграция)
---
### Урок 3
**ETL - процесс предподготовке данных. Может выполнятся несколько раз.**
1. Получение данных
2. Очистка данных или заполнение пропусков
    - Интерполяция значений (заполнение пропусков близкими значениями). **Не работает для категориальных данных**, но подходит для числовых и ранговых. Возможно использование для категориальных и числовых возможен вариант с заполнением полей значениями которые точно не встретятся в норме и не будут учавствовать в анализе. Сам по себе пропуск данных исключает возможность использования экзепляра данных для обучения.
    > Мусор на входе - мусор на выходе
3. Объединение данных
---
### Урок 4
**EDA - разведочный или исследовательский анализ данных.**
Задачи EDA:
1. Оценка распределения параметров (равномерное распределение (если имется нормально распределенные числовые данные для линейной регрессии), бимодальное *(возможно требуется разбить данные на две категории, чтобы анализировать их поотдельности)*, по Пуасону или оно отсутствует *(возможно для категориальных данных)*). Предположениео том какая модель машинного обучения может получится и сделать выбор
2. **Поиск пропусков данных** или нулевых значений и аномалий
3. Корреляция. Определиться с поиском наиболее значимых параметров.
4. Примеры данных
В результате даются рекомендации и делаются выводы для **ETL**.
---
### Урок 5
# Препроцессинг данных:
1. Нормирование *(приведение к диапазону 0 <-> 1)*:

| Параметр |  |  |  |  |  |  |  |  |  |  |  |
|-----|------|------|------|------|------|------|------|------|------|------|------|
| **X** | 1 | 2 | 4 | 5 | **->** | 0 | 1/4 | 3/4 | 1 |
| **Y** | -100 | 300 | 1100|  |**->** | 0 | 1/3 | 1|

> X -> (X - min) / (max - min)

На таких данных можно посчитать любую модель, но если нужно понять какие данные привели к конкретным результатам, то нужно выполнить обратное преобразование.

> X -> (X - avg) / std
2. Z нормирование *(в случае если данные имеют нормальное распределение)* *(приведение к диапазону -3 <-> 3)*
3. Приведение к единичным векторам: [OHE](https://pythonpip.ru/osnovy/one-hot-encoding-python?ysclid=leqrcvf1gd978117076/ "Что такое One-Hot Encoding")
4. Циклические переменные
> Z -> (sin Z; cos Z)

| Параметр |  |  |  |  |  |  |  |  |  |  |  |
|-----|------|------|------|------|------|------|------|------|------|------|------|
| **Z** | 5 | 120 | 360 | **->** |  |  |  |
| **sin Z** | 0,087 | 0,866 | 0 |**->** |  |  | |
| **cos Z** | 0,996 | −0,5 | 1 |**->** |  |  |  |

Преобразование выполняется по правилу:
>sin Z + 1 / 2

>cos Z + 1 / 2
---
### Урок 6
# Разбиение выборки
Разбиение выборки данных для проверки должно соответствовать пропорции *80 / 20* эти доли соотвествуют **Обучающей и Проверочной выборке**

> Сравнивать модели необходимо только с учетом того что они обучались на одинаковых объемах данных

| Общая выборка | 1 000 000 | **I** | K - fold |  |Обучение и валидация|
|-----|------|------|------|------|------|
| Первичная выборка | 1 000 000 | **I** |  |  |  |
| **Обучающая** | 800 000 | **I** | **->** | 160 000 * 5 |  |
| **Проверочная** | 200 000 | **I** |**->** | * |  |

Такое соотношение выбрано:
1. Чтобы хорошо обучить модель (чтобы она получила достаточно большое количество исходных данных)
2. Найти все ошибки и понять где модель обучилась недостаточно хорошо
# Оптимизация гиперпараметров:
1. Перекрестная валидация - используется для улучшения модели. Заключается в раздроблении данных на более мелкие равные части и поочередное обучение и проверку модели на разных частях. Позволяет понять насколько модель хорошо работает на обучающей выборке.
> Капитальное разбиение используется для итоговой оценки и сравнения моделей и метрик по точности.

2. Обучающая и валидационные выборки - используются для обучения **нейросетей**. 

